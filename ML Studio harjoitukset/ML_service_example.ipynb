{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://yacineyakoubi-blog.com/wp-content/uploads/2018/11/mlworkbench_icon-300x300.png\"/>\n",
    "\n",
    "# Working with Azure ML Service Workspace\n",
    "Azure Machine Learning provides a cloud-based environment you can use to prep data, train, test, deploy, manage, and track machine learning models. \n",
    "\n",
    "<a href=\"https://github.com/Azure/MachineLearningNotebooks\">This repository</a> contains example notebooks demonstrating the Azure Machine Learning Python SDK which allows you to build, train, deploy and manage machine learning solutions using Azure. The AML SDK allows you the choice of using local or cloud compute resources, while managing and maintaining the complete data science workflow from the cloud.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/machine-learning/service/media/concept-azure-machine-learning-architecture/workflow.png\"/>\n",
    "\n",
    "In this Notebook, you will learn how to train models in a managed experiment.\n",
    "\n",
    "## Library imports & configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZURE imports:\n",
    "from azureml.core import Experiment, Workspace, Run\n",
    "import azureml.core\n",
    "from tqdm import tqdm\n",
    "\n",
    "# SKLEARN imports:\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Other imports:\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "print(\"This notebook was created using SDK version 1.0.62,\\n\\\n",
    "you are currently running version\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next, get Azure ML Service Workspace configuration from a json-file. This avoids hard-coding and makes the notebook more generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory:\n",
    "os.chdir('path')\n",
    "\n",
    "# Load conf-file:\n",
    "with open('ws_conf.json', 'r') as f:\n",
    "    conf = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "When the configuration has been loaded, we can proceed to connect to the ML Workspace (this will pop-up a new interactive window for login):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(name = conf['ws_name'], \n",
    "                   subscription_id = conf['subscription_id'], \n",
    "                   resource_group = conf['resource_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Example data\n",
    "\n",
    "Load the Boston houses exampe dataset from `sklearn` inbuilt datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "feature_names = boston.feature_names\n",
    "\n",
    "print('Numeber of rows in data:',X.shape[0],'\\n')\n",
    "print('Feature names:',feature_names,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Get statistical summary of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns = feature_names)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next, split data into `train` and `test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y,\n",
    "                 test_size = 0.197,\n",
    "                 random_state = 0)\n",
    "\n",
    "data = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
    "        \"test\": {\"X\": X_test, \"y\": y_test}}\n",
    "\n",
    "# Get data sizes:\n",
    "{k : v['X'].shape[0] for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Prepare experiment\n",
    "Here we'll define any objects that will be iterated over in a run of the experiment.\n",
    "\n",
    "As an example, create a dictionary that contains several models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'linear_model' : Ridge(alpha = 0.2),\n",
    "    'Random_Forest' : RandomForestRegressor(n_estimators = 10, random_state = 123),\n",
    "    'kNN' : KNeighborsRegressor(n_neighbors = 5, leaf_size = 10, p = 1)\n",
    "}\n",
    "estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Run experiment\n",
    "\n",
    "First, create new Experiment or connect to existing one in your workspace: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace = ws, \n",
    "                        name = 'logging-api-test')\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above table, there are is a link to access the experiment on Azure portal.\n",
    "\n",
    "Next, start a new run in the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start logging for the run\n",
    "run = experiment.start_logging()\n",
    "\n",
    "# access the run id for use later\n",
    "run_id = run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the run is active, iterate over models and log their performance. \n",
    "\n",
    "Also, save the model objects for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in estimators.items():\n",
    "    \n",
    "    # Fit model:\n",
    "    model.fit(data[\"train\"][\"X\"], \n",
    "              data[\"train\"][\"y\"])\n",
    "    \n",
    "    # Make predictions for testing data:\n",
    "    preds = model.predict(data[\"test\"][\"X\"])\n",
    "    \n",
    "    # Logging:\n",
    "    mse = mean_squared_error(preds, data[\"test\"][\"y\"])\n",
    "    print(algo,', MSE: ',round(mse,2),'\\n',sep='')\n",
    "    run.log('algorithm', algo)\n",
    "    run.log('mse', mse)\n",
    "    \n",
    "    # Save the model to the outputs directory for capture:\n",
    "    model_file_name = 'outputs/'+algo+'.pkl'\n",
    "\n",
    "    joblib.dump(value = model, filename = model_file_name)\n",
    "\n",
    "    # upload the model file explicitly into artifacts :\n",
    "    run.upload_file(name = model_file_name, \n",
    "                    path_or_stream = model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End run:\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the status of the current run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = list(experiment.get_runs())\n",
    "[x for x in runs if x.id == run_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now you can go to the Azure portal and view the run results.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://cdn.thenewstack.io/media/2018/10/5ca8f804-az-ml-4-1024x393.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
